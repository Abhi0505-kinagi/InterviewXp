[
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "CORS",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "client.node_modules.flatted.python.flatted",
        "description": "client.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "client.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "client.node_modules.flatted.python.flatted",
        "description": "client.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "client.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "client.node_modules.flatted.python.flatted",
        "description": "client.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "client.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "client.node_modules.flatted.python.flatted",
        "description": "client.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "client.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "try_load",
        "kind": 2,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "def try_load(path):\n    # try given path, then path relative to this file\n    try:\n        model = joblib.load(path)\n        print(f\"Loaded model from {path}\")\n        return model\n    except FileNotFoundError:\n        alt = os.path.join(os.path.dirname(__file__), path)\n        try:\n            model = joblib.load(alt)",
        "detail": "ml_integration.app",
        "documentation": {}
    },
    {
        "label": "format_response",
        "kind": 2,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "def format_response(model_name, text, prediction, probability, label_map):\n    decision = (\n        \"Selected\" if probability >= CONFIDENCE_THRESHOLD else\n        \"Rejected\" if probability <= (1 - CONFIDENCE_THRESHOLD) else\n        \"Review Required\"\n    )\n    return {\n        \"status\": \"success\",\n        \"model\": model_name,\n        \"input_text\": text,",
        "detail": "ml_integration.app",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "def home():\n    status = \"running\" if (sentiment_model is not None and selection_model is not None) else \"partial\"\n    details = {\n        \"sentiment_loaded\": sentiment_model is not None,\n        \"selection_loaded\": selection_model is not None\n    }\n    return jsonify({\n        \"status\": status,\n        \"message\": \"ML Backend is running\",\n        \"details\": details",
        "detail": "ml_integration.app",
        "documentation": {}
    },
    {
        "label": "predict_sentiment",
        "kind": 2,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "def predict_sentiment():\n    data = request.json\n    if not data or \"text\" not in data:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": \"Text field is required\"\n        }), 400\n    if sentiment_model is None:\n        return jsonify({\"status\": \"error\", \"message\": \"Sentiment model not loaded\"}), 500\n    text = data[\"text\"]",
        "detail": "ml_integration.app",
        "documentation": {}
    },
    {
        "label": "predict_selection",
        "kind": 2,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "def predict_selection():\n    data = request.json\n    if not data or \"text\" not in data:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": \"Text field is required\"\n        }), 400\n    if selection_model is None:\n        return jsonify({\"status\": \"error\", \"message\": \"Selection model not loaded\"}), 500\n    text = data[\"text\"]",
        "detail": "ml_integration.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "app = Flask(__name__)\nCORS(app, resources={r\"/api/ml/*\": {\"origins\": \"*\"}}) \n# Load models (gracefully handle missing files)\nimport os\ndef try_load(path):\n    # try given path, then path relative to this file\n    try:\n        model = joblib.load(path)\n        print(f\"Loaded model from {path}\")\n        return model",
        "detail": "ml_integration.app",
        "documentation": {}
    },
    {
        "label": "sentiment_model",
        "kind": 5,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "sentiment_model = try_load(\"interview_sentiment_model.pkl\")\nselection_model = try_load(\"interview_selection_model.pkl\")\nCONFIDENCE_THRESHOLD = 0.65\ndef format_response(model_name, text, prediction, probability, label_map):\n    decision = (\n        \"Selected\" if probability >= CONFIDENCE_THRESHOLD else\n        \"Rejected\" if probability <= (1 - CONFIDENCE_THRESHOLD) else\n        \"Review Required\"\n    )\n    return {",
        "detail": "ml_integration.app",
        "documentation": {}
    },
    {
        "label": "selection_model",
        "kind": 5,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "selection_model = try_load(\"interview_selection_model.pkl\")\nCONFIDENCE_THRESHOLD = 0.65\ndef format_response(model_name, text, prediction, probability, label_map):\n    decision = (\n        \"Selected\" if probability >= CONFIDENCE_THRESHOLD else\n        \"Rejected\" if probability <= (1 - CONFIDENCE_THRESHOLD) else\n        \"Review Required\"\n    )\n    return {\n        \"status\": \"success\",",
        "detail": "ml_integration.app",
        "documentation": {}
    },
    {
        "label": "CONFIDENCE_THRESHOLD",
        "kind": 5,
        "importPath": "ml_integration.app",
        "description": "ml_integration.app",
        "peekOfCode": "CONFIDENCE_THRESHOLD = 0.65\ndef format_response(model_name, text, prediction, probability, label_map):\n    decision = (\n        \"Selected\" if probability >= CONFIDENCE_THRESHOLD else\n        \"Rejected\" if probability <= (1 - CONFIDENCE_THRESHOLD) else\n        \"Review Required\"\n    )\n    return {\n        \"status\": \"success\",\n        \"model\": model_name,",
        "detail": "ml_integration.app",
        "documentation": {}
    }
]